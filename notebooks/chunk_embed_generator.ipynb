{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "!pip install sentence-transformers PyPDF2\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from google.colab import files\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# --- Model selection UI ---\n",
    "model_options = [\n",
    "    ('English MiniLM', 'all-MiniLM-L6-v2'),\n",
    "    ('Japanese/Multilingual (LaBSE)', 'sentence-transformers/LaBSE'),\n",
    "    ('Japanese S-BERT', 'sonoisa/sentence-bert-base-ja-mean-tokens-v2'),\n",
    "]\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=model_options,\n",
    "    value='all-MiniLM-L6-v2',\n",
    "    description='Model:'\n",
    ")\n",
    "\n",
    "chunk_size_slider = widgets.IntSlider(\n",
    "    value=200,\n",
    "    min=50,\n",
    "    max=2048,\n",
    "    step=50,\n",
    "    description='Chunk size:'\n",
    ")\n",
    "\n",
    "display(model_dropdown)\n",
    "display(chunk_size_slider)\n",
    "\n",
    "# PDF upload\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Initialize selected model\n",
    "model = SentenceTransformer(model_dropdown.value)\n",
    "\n",
    "# PDF to text extraction\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_reader = PyPDF2.PdfReader(open(pdf_path, \"rb\"))\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text() or \"\"\n",
    "    # Check if extracted text is empty (image-only PDF)\n",
    "    if not text.strip():\n",
    "        print(\"No extractable text found: This PDF appears to be image-only. Skipping.\")\n",
    "        return \"\"\n",
    "    return text\n",
    "\n",
    "\n",
    "# Chunk splitting\n",
    "def chunk_text(text, chunk_size=200):\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "\n",
    "def make_chunks_and_embeddings(text, chunk_size=200):\n",
    "    chunks = chunk_text(text, chunk_size)\n",
    "    embeddings = model.encode(chunks)\n",
    "    return chunks, embeddings\n",
    "\n",
    "\n",
    "# New function: Save chunks.json, embeddings.npy, embeddings.csv, metadata.json together as a .zip archive\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "def export_zip_archive(base, chunks, embeddings, metadata):\n",
    "    \"\"\"\n",
    "    Save chunks, embeddings (both .npy and .csv formats), and metadata into a .zip archive.\n",
    "    chunks: list of text chunks\n",
    "    embeddings: numpy array\n",
    "    metadata: dict containing metadata information\n",
    "    \"\"\"\n",
    "    # Create files in memory buffer temporarily\n",
    "    chunks_json = json.dumps(chunks, ensure_ascii=False).encode('utf-8')\n",
    "    metadata_json = json.dumps(metadata, ensure_ascii=False).encode('utf-8')\n",
    "    embeddings_bytes_io = io.BytesIO()\n",
    "    np.save(embeddings_bytes_io, embeddings)\n",
    "    embeddings_bytes = embeddings_bytes_io.getvalue()\n",
    "    # Create CSV in-memory string buffer\n",
    "    embeddings_csv_io = io.StringIO()\n",
    "    np.savetxt(embeddings_csv_io, embeddings, delimiter=\",\")\n",
    "    embeddings_csv_str = embeddings_csv_io.getvalue().encode('utf-8')\n",
    "\n",
    "    zip_path = f\"/content/{base}.zip\"\n",
    "    with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        zf.writestr(\"chunks.json\", chunks_json)\n",
    "        zf.writestr(\"embeddings.npy\", embeddings_bytes)\n",
    "        zf.writestr(\"embeddings.csv\", embeddings_csv_str)\n",
    "        zf.writestr(\"metadata.json\", metadata_json)\n",
    "        print(f\"Exported ZIP archive: {zip_path}\")\n",
    "        print(\"Included embeddings.csv in the ZIP archive as well.\")\n",
    "\n",
    "\n",
    "for pdf_path in uploaded.keys():\n",
    "    print(f\"Processing {pdf_path} ...\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    # Skip processing if the PDF is image-only (no extractable text)\n",
    "    if not text:\n",
    "        continue\n",
    "    chunks, embeddings = make_chunks_and_embeddings(text, chunk_size=chunk_size_slider.value)\n",
    "    base = pdf_path.rsplit(\".\", 1)[0]\n",
    "    with open(f\"/content/{base}_chunks.json\", \"w\") as f:\n",
    "        json.dump(chunks, f, ensure_ascii=False)\n",
    "    np.save(f\"/content/{base}_embeddings.npy\", embeddings)\n",
    "    np.savetxt(f\"/content/{base}_embeddings.csv\", embeddings, delimiter=\",\")\n",
    "    print(f\"Saved: {base}_chunks.json, {base}_embeddings.npy, {base}_embeddings.csv\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- New cell ---\n",
    "# Export chunks.json, embeddings.npy, embeddings.csv, metadata.json together as a .zip archive\n",
    "\n",
    "metadata = {\n",
    "    \"original_pdf\": pdf_path,\n",
    "    \"chunk_size\": chunk_size_slider.value,\n",
    "    \"model_used\": model_dropdown.value,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "export_zip_archive(base, chunks, embeddings, metadata)"
   ],
   "id": "2c2fb70d6f330e4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
