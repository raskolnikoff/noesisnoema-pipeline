{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 1: Install dependencies\n",
    "## This notebook converts a downloaded Llama-3 model (e.g., Llama-3-8B-Instruct) to GGUF format for use with llama.cpp.\n",
    "\n",
    "```python\n",
    "!pip install --quiet git+https://github.com/ggerganov/llama.cpp\n",
    "!pip install --quiet huggingface_hub transformers sentencepiece"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2: Authenticate HuggingFace\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ],
   "id": "b95a48346fa98978",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 3: Download model weights\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Change model_id if you want a different model (Llama-3-8B-Instruct, Llama-3-70B, etc.)\n",
    "model_id = \"meta-llama/Llama-3-8B-Instruct\"\n",
    "\n",
    "# This will create a directory in /content\n",
    "weights_dir = snapshot_download(repo_id=model_id, allow_patterns=[\"*.bin\", \"*.json\", \"*.model\", \"*.txt\"])\n",
    "print(f\"Model downloaded to: {weights_dir}\")"
   ],
   "id": "700efaeeefcd5b1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4: Clone llama.cpp repository\n",
    "!git clone https://github.com/ggerganov/llama.cpp.git\n",
    "%cd llama.cpp/scripts"
   ],
   "id": "537bcd62ae20467",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 5: Convert Llama-3 model to GGUF format\n",
    "# You can save the GGUF model file directly to Google Drive by setting the path below.\n",
    "# For example: gguf_out = '/content/drive/MyDrive/llama3-8b.gguf' (requires Drive to be mounted).\n",
    "\n",
    "import os\n",
    "\n",
    "gguf_out = \"/content/llama3-8b.gguf\"\n",
    "# If you want to save directly to Google Drive, set gguf_out = '/content/drive/MyDrive/llama3-8b.gguf' (requires Drive mounted).\n",
    "# Run conversion script (for Llama-3 only)\n",
    "!python3 convert-llama3-to-gguf.py \\\n",
    "  --outtype f16 \\\n",
    "  --outfile {gguf_out} \\\n",
    "  {weights_dir}\n",
    "\n",
    "print(f\"GGUF model saved to: {gguf_out}\")"
   ],
   "id": "74f0a0e7818913c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 6: Download the GGUF model file\n",
    "from google.colab import files\n",
    "files.download(gguf_out)"
   ],
   "id": "b9c8b6026d46c27b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
